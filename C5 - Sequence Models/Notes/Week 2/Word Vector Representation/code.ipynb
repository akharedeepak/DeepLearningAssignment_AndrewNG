{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"code.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Xet2q1MLCGV40NCnVyOkwkIVWgGTpnYf","authorship_tag":"ABX9TyN/w7WiW7VUEy1JVfD+2i+/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pR2rcP9_x-C5","executionInfo":{"status":"ok","timestamp":1628517353819,"user_tz":240,"elapsed":614,"user":{"displayName":"Deepak Akhare","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEAbLioRjH-vFkkktO6xoQOZCm1tYRRfKLX_nVsw=s64","userId":"15729154757356582151"}},"outputId":"d2580b2f-8520-46a9-99a5-7865583afdd8"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","%cd /content/drive/My\\ Drive/Colab_Notebooks"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/My Drive/Colab_Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fEC2K6msymV3","executionInfo":{"status":"ok","timestamp":1628517354507,"user_tz":240,"elapsed":561,"user":{"displayName":"Deepak Akhare","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEAbLioRjH-vFkkktO6xoQOZCm1tYRRfKLX_nVsw=s64","userId":"15729154757356582151"}},"outputId":"deb38ad2-a4c9-4d37-c8c5-fd8c6fbef909"},"source":["%cd coursera-deep-learning-specialization-master/C5\\ -\\ Sequence\\ Models/Week\\ 2/Word\\ Vector\\ Representation"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab_Notebooks/coursera-deep-learning-specialization-master/C5 - Sequence Models/Week 2/Word Vector Representation\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zY_U07wly3pN","executionInfo":{"status":"ok","timestamp":1628517355116,"user_tz":240,"elapsed":617,"user":{"displayName":"Deepak Akhare","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEAbLioRjH-vFkkktO6xoQOZCm1tYRRfKLX_nVsw=s64","userId":"15729154757356582151"}},"outputId":"741a16d4-4a08-419d-ae7f-2340b284e58f"},"source":["%tensorflow_version 1.x"],"execution_count":4,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-KWrHHXIy6v6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628517360962,"user_tz":240,"elapsed":5855,"user":{"displayName":"Deepak Akhare","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEAbLioRjH-vFkkktO6xoQOZCm1tYRRfKLX_nVsw=s64","userId":"15729154757356582151"}},"outputId":"5dfa1bc4-b1cf-4f1f-b9ab-ba1a4536065d"},"source":["import numpy as np\n","from w2v_utils import *"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"jZUcObXtMmKB","executionInfo":{"status":"ok","timestamp":1628517748943,"user_tz":240,"elapsed":7827,"user":{"displayName":"Deepak Akhare","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEAbLioRjH-vFkkktO6xoQOZCm1tYRRfKLX_nVsw=s64","userId":"15729154757356582151"}}},"source":["words, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"wRi8tBzEMuxx","executionInfo":{"status":"ok","timestamp":1628518363162,"user_tz":240,"elapsed":112,"user":{"displayName":"Deepak Akhare","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEAbLioRjH-vFkkktO6xoQOZCm1tYRRfKLX_nVsw=s64","userId":"15729154757356582151"}}},"source":["def cosine_similarity(u, v):\n","  cosine_similarity = np.dot(u.T, v) / ( np.sqrt(np.dot(u.T,u)) * np.sqrt(np.dot(v.T,v)) )\n","  return cosine_similarity"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TNeohM4kQi8H","executionInfo":{"status":"ok","timestamp":1628518507773,"user_tz":240,"elapsed":143,"user":{"displayName":"Deepak Akhare","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEAbLioRjH-vFkkktO6xoQOZCm1tYRRfKLX_nVsw=s64","userId":"15729154757356582151"}},"outputId":"38f4afae-7e14-4b62-bb53-dcd57fad34ff"},"source":["father = word_to_vec_map[\"father\"]\n","mother = word_to_vec_map[\"mother\"]\n","ball = word_to_vec_map[\"ball\"]\n","crocodile = word_to_vec_map[\"crocodile\"]\n","france = word_to_vec_map[\"france\"]\n","italy = word_to_vec_map[\"italy\"]\n","paris = word_to_vec_map[\"paris\"]\n","rome = word_to_vec_map[\"rome\"]\n","\n","print(\"cosine_similarity(father, mother) = \", cosine_similarity(father, mother))\n","print(\"cosine_similarity(ball, crocodile) = \",cosine_similarity(ball, crocodile))\n","print(\"cosine_similarity(france - paris, rome - italy) = \",cosine_similarity(france - paris, rome - italy))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["cosine_similarity(father, mother) =  0.8909038442893615\n","cosine_similarity(ball, crocodile) =  0.2743924626137942\n","cosine_similarity(france - paris, rome - italy) =  -0.6751479308174202\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NnI2cv1RRGOx","executionInfo":{"status":"ok","timestamp":1628519533239,"user_tz":240,"elapsed":114,"user":{"displayName":"Deepak Akhare","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEAbLioRjH-vFkkktO6xoQOZCm1tYRRfKLX_nVsw=s64","userId":"15729154757356582151"}}},"source":["def complete_analogy(word_a, word_b, word_c, word_to_vec_map):\n","\n","  word_a, word_b, word_c = word_a.lower(), word_b.lower(), word_c.lower()\n","  e_a, e_b, e_c = word_to_vec_map[word_a], word_to_vec_map[word_b], word_to_vec_map[word_c]\n","\n","  words = word_to_vec_map.keys()\n","  max_cosine_sim = -100              # Initialize max_cosine_sim to a large negative number\n","  best_word = None                   # Initialize best_word with None, it will help keep track of the word to output\n","\n","  for w in words:\n","    if w in [word_a, word_b, word_c]:\n","      continue\n","\n","    cosine_sim = cosine_similarity(word_to_vec_map[w]-e_c, e_b - e_a)\n","\n","    if cosine_sim > max_cosine_sim:\n","      max_cosine_sim = cosine_sim\n","      best_word = w\n","    \n","  return best_word"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vv9S9MqZRv8X","executionInfo":{"status":"ok","timestamp":1628519681069,"user_tz":240,"elapsed":20207,"user":{"displayName":"Deepak Akhare","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEAbLioRjH-vFkkktO6xoQOZCm1tYRRfKLX_nVsw=s64","userId":"15729154757356582151"}},"outputId":"4f573865-e38e-4a07-bb1a-dac4c71b4a55"},"source":["triads_to_try = [('italy', 'italian', 'spain'), ('india', 'delhi', 'japan'), ('man', 'woman', 'boy'), ('small', 'smaller', 'large'), ('small', 'smaller', 'big')]\n","for triad in triads_to_try:\n","    print ('{} -> {} :: {} -> {}'.format( *triad, complete_analogy(*triad,word_to_vec_map)))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["italy -> italian :: spain -> spanish\n","india -> delhi :: japan -> tokyo\n","man -> woman :: boy -> girl\n","small -> smaller :: large -> larger\n","small -> smaller :: big -> competitors\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MTc_zO5fVMk_","executionInfo":{"status":"ok","timestamp":1628519835222,"user_tz":240,"elapsed":208,"user":{"displayName":"Deepak Akhare","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEAbLioRjH-vFkkktO6xoQOZCm1tYRRfKLX_nVsw=s64","userId":"15729154757356582151"}},"outputId":"b9909fac-cf37-422b-c45a-3cd83aa5c6ea"},"source":["g = word_to_vec_map['woman'] - word_to_vec_map['man']\n","print(g)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["[-0.087144    0.2182     -0.40986    -0.03922    -0.1032      0.94165\n"," -0.06042     0.32988     0.46144    -0.35962     0.31102    -0.86824\n","  0.96006     0.01073     0.24337     0.08193    -1.02722    -0.21122\n","  0.695044   -0.00222     0.29106     0.5053     -0.099454    0.40445\n","  0.30181     0.1355     -0.0606     -0.07131    -0.19245    -0.06115\n"," -0.3204      0.07165    -0.13337    -0.25068714 -0.14293    -0.224957\n"," -0.149       0.048882    0.12191    -0.27362    -0.165476   -0.20426\n","  0.54376    -0.271425   -0.10245    -0.32108     0.2516     -0.33455\n"," -0.04371     0.01258   ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qxpv0vVTWIdN","executionInfo":{"status":"ok","timestamp":1628519918021,"user_tz":240,"elapsed":120,"user":{"displayName":"Deepak Akhare","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEAbLioRjH-vFkkktO6xoQOZCm1tYRRfKLX_nVsw=s64","userId":"15729154757356582151"}},"outputId":"010dfe8f-5ce8-47d8-bba8-9503822233a2"},"source":["print ('List of names and their similarities with constructed vector:')\n","\n","# girls and boys name\n","name_list = ['john', 'marie', 'sophie', 'ronaldo', 'priya', 'rahul', 'danielle', 'reza', 'katy', 'yasmin']\n","\n","for w in name_list:\n","    print (w, cosine_similarity(word_to_vec_map[w], g))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["List of names and their similarities with constructed vector:\n","john -0.23163356145973724\n","marie 0.315597935396073\n","sophie 0.31868789859418784\n","ronaldo -0.31244796850329437\n","priya 0.17632041839009402\n","rahul -0.16915471039231716\n","danielle 0.24393299216283895\n","reza -0.07930429672199553\n","katy 0.2831068659572615\n","yasmin 0.2331385776792876\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2AN3vAIFWeil","executionInfo":{"status":"ok","timestamp":1628519988252,"user_tz":240,"elapsed":112,"user":{"displayName":"Deepak Akhare","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEAbLioRjH-vFkkktO6xoQOZCm1tYRRfKLX_nVsw=s64","userId":"15729154757356582151"}},"outputId":"4ab3041b-d39c-4e2f-c0f5-dd3dc8564ea8"},"source":["print('Other words and their similarities:')\n","word_list = ['lipstick', 'guns', 'science', 'arts', 'literature', 'warrior','doctor', 'tree', 'receptionist', \n","             'technology',  'fashion', 'teacher', 'engineer', 'pilot', 'computer', 'singer']\n","for w in word_list:\n","    print (w, cosine_similarity(word_to_vec_map[w], g))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Other words and their similarities:\n","lipstick 0.2769191625638267\n","guns -0.1888485567898898\n","science -0.06082906540929701\n","arts 0.008189312385880337\n","literature 0.06472504433459932\n","warrior -0.20920164641125288\n","doctor 0.11895289410935041\n","tree -0.07089399175478091\n","receptionist 0.3307794175059374\n","technology -0.13193732447554302\n","fashion 0.03563894625772699\n","teacher 0.17920923431825664\n","engineer -0.0803928049452407\n","pilot 0.0010764498991916937\n","computer -0.10330358873850498\n","singer 0.1850051813649629\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w60EZ9E8Wvry","executionInfo":{"status":"ok","timestamp":1628520572757,"user_tz":240,"elapsed":111,"user":{"displayName":"Deepak Akhare","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEAbLioRjH-vFkkktO6xoQOZCm1tYRRfKLX_nVsw=s64","userId":"15729154757356582151"}}},"source":["def neutralize(word, g, word_to_vec_map):\n","\n","  e = word_to_vec_map[word]\n","  e_biascomponent = np.dot(e, g) *g/(np.linalg.norm(g)**2) \n","  e_debiased = e-e_biascomponent\n","  \n","  return e_debiased"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pKc9ozVUYg7P","executionInfo":{"status":"ok","timestamp":1628520793720,"user_tz":240,"elapsed":92,"user":{"displayName":"Deepak Akhare","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEAbLioRjH-vFkkktO6xoQOZCm1tYRRfKLX_nVsw=s64","userId":"15729154757356582151"}},"outputId":"0dd121f0-5dee-4d61-f15d-3a3a2ca46e50"},"source":["e = \"receptionist\"\n","print(\"cosine similarity between \" + e + \" and g, before neutralizing: \", cosine_similarity(word_to_vec_map[e], g))\n","\n","e_debiased = neutralize(e, g, word_to_vec_map)\n","print(\"cosine similarity between \" + e + \" and g, after neutralizing: \", cosine_similarity(e_debiased, g))"],"execution_count":44,"outputs":[{"output_type":"stream","text":["cosine similarity between receptionist and g, before neutralizing:  0.3307794175059374\n","cosine similarity between receptionist and g, after neutralizing:  -3.535098790543231e-18\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pU4EScVUY7nm","executionInfo":{"status":"ok","timestamp":1628520947362,"user_tz":240,"elapsed":122,"user":{"displayName":"Deepak Akhare","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEAbLioRjH-vFkkktO6xoQOZCm1tYRRfKLX_nVsw=s64","userId":"15729154757356582151"}}},"source":["def equalize(pair, bias_axis, word_to_vec_map):\n","    \n","    # Step 1: Select word vector representation of \"word\". Use word_to_vec_map. (≈ 2 lines)\n","    w1, w2 = pair\n","    e_w1, e_w2 = word_to_vec_map[w1], word_to_vec_map[w2]\n","    \n","    # Step 2: Compute the mean of e_w1 and e_w2 (≈ 1 line)\n","    mu = (e_w1+e_w2)/2\n","\n","    # Step 3: Compute the projections of mu over the bias axis and the orthogonal axis (≈ 2 lines)\n","    mu_B = np.dot(mu, bias_axis)/np.linalg.norm(bias_axis)**2 * bias_axis\n","    mu_orth = mu-mu_B\n","\n","    # Step 4: Use equations (7) and (8) to compute e_w1B and e_w2B (≈2 lines)\n","    e_w1B = np.dot(e_w1, bias_axis)/np.linalg.norm(bias_axis)**2 * bias_axis\n","    e_w2B = np.dot(e_w2, bias_axis)/np.linalg.norm(bias_axis)**2 * bias_axis\n","        \n","    # Step 5: Adjust the Bias part of e_w1B and e_w2B using the formulas (9) and (10) given above (≈2 lines)\n","    corrected_e_w1B = np.sqrt(np.abs(1-np.linalg.norm(mu_orth)**2))*(e_w1B-mu_B)/np.linalg.norm(e_w1-mu_orth-mu_B)\n","    corrected_e_w2B = np.sqrt(np.abs(1-np.linalg.norm(mu_orth)**2))*(e_w2B-mu_B)/np.linalg.norm(e_w2-mu_orth-mu_B)\n","\n","    # Step 6: Debias by equalizing e1 and e2 to the sum of their corrected projections (≈2 lines)\n","    e1 = corrected_e_w1B+mu_orth\n","    e2 = corrected_e_w2B+mu_orth\n","                            \n","    return e1, e2"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CNhnNcUZaZ2K","executionInfo":{"status":"ok","timestamp":1628520966053,"user_tz":240,"elapsed":121,"user":{"displayName":"Deepak Akhare","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEAbLioRjH-vFkkktO6xoQOZCm1tYRRfKLX_nVsw=s64","userId":"15729154757356582151"}},"outputId":"0ef9c0a6-02a7-4b3c-a1a9-bf9ccbe1d789"},"source":["print(\"cosine similarities before equalizing:\")\n","print(\"cosine_similarity(word_to_vec_map[\\\"man\\\"], gender) = \", cosine_similarity(word_to_vec_map[\"man\"], g))\n","print(\"cosine_similarity(word_to_vec_map[\\\"woman\\\"], gender) = \", cosine_similarity(word_to_vec_map[\"woman\"], g))\n","print()\n","e1, e2 = equalize((\"man\", \"woman\"), g, word_to_vec_map)\n","print(\"cosine similarities after equalizing:\")\n","print(\"cosine_similarity(e1, gender) = \", cosine_similarity(e1, g))\n","print(\"cosine_similarity(e2, gender) = \", cosine_similarity(e2, g))"],"execution_count":46,"outputs":[{"output_type":"stream","text":["cosine similarities before equalizing:\n","cosine_similarity(word_to_vec_map[\"man\"], gender) =  -0.11711095765336832\n","cosine_similarity(word_to_vec_map[\"woman\"], gender) =  0.35666618846270376\n","\n","cosine similarities after equalizing:\n","cosine_similarity(e1, gender) =  -0.7004364289309387\n","cosine_similarity(e2, gender) =  0.7004364289309387\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wRIk6r16aeaG"},"source":[""],"execution_count":null,"outputs":[]}]}